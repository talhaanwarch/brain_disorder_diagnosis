{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all channels",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/Schizophrenia14/blob/master/all_channels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAZkeuKAh84E"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZTedeQ8kjcX"
      },
      "source": [
        "In this approach data is segmented and feature are calculated for each segment. Then these features are averaged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2dWHVU6--Do"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9bXPLMDCobm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1424b00a-6c59-4c86-80e2-4b8a2af7668e"
      },
      "source": [
        "!pip install wfdb\n",
        "!pip install mne\n",
        "# !pip install nitime\n",
        "# !pip install nolds"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a0/922d06ec737e219a9f45545432842e68a84e8b52f292704056eea1d35e41/wfdb-3.1.1.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2016.8.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2020.6.20)\n",
            "Requirement already satisfied: chardet>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.0.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.10.0)\n",
            "Requirement already satisfied: idna>=2.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.17.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.2.2)\n",
            "Collecting mne>=0.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/0e/6448521738d3357c205795fd5846d023bd7935bb83ba93a1ba0f7124205e/mne-0.21.2-py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 11.4MB/s \n",
            "\u001b[?25hCollecting nose>=1.3.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.1.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.4 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2018.9)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.4.1)\n",
            "Requirement already satisfied: six>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.15.0)\n",
            "Requirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.0)\n",
            "Collecting threadpoolctl>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3>=1.22 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.24.3)\n",
            "Building wheels for collected packages: wfdb\n",
            "  Building wheel for wfdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wfdb: filename=wfdb-3.1.1-cp36-none-any.whl size=117828 sha256=ef7c6bcd1d12cf866cca2accd478388998aca040827ee2243222205a86a75620\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/d0/c1/90538d266ccba2d1076fbc9970192c7ea1a09c99df3e65c69b\n",
            "Successfully built wfdb\n",
            "Installing collected packages: mne, nose, threadpoolctl, wfdb\n",
            "Successfully installed mne-0.21.2 nose-1.3.7 threadpoolctl-2.1.0 wfdb-3.1.1\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.21.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN2iOjELEkWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c376a314-5362-4bff-f0ff-d262cb18ecdc"
      },
      "source": [
        "!pip install git+https://github.com/forrestbao/pyeeg.git\n",
        "!pip install git+https://github.com/raphaelvallat/entropy.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-x3gv_nuc\n",
            "  Running command git clone -q https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-x3gv_nuc\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyeeg==0.4.4) (1.18.5)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28122 sha256=648be59966b71469337c3a51508a92274a418fab7ba0c80107f3fe8e5f9f18d8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jjkc7xlf/wheels/2d/3f/ad/106d4fc80b61d1ea1fc18e76e7439fd98aa043d83d58eae741\n",
            "Successfully built pyeeg\n",
            "Installing collected packages: pyeeg\n",
            "Successfully installed pyeeg-0.4.4\n",
            "Collecting git+https://github.com/raphaelvallat/entropy.git\n",
            "  Cloning https://github.com/raphaelvallat/entropy.git to /tmp/pip-req-build-6zm_gupv\n",
            "  Running command git clone -q https://github.com/raphaelvallat/entropy.git /tmp/pip-req-build-6zm_gupv\n",
            "Building wheels for collected packages: entropy\n",
            "  Building wheel for entropy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for entropy: filename=entropy-0.1.2-cp36-none-any.whl size=15611 sha256=bb904fe692da18a5e2238e704e679a751864115efe9fb9a823adab3250a4e72c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e7e832qh/wheels/60/ed/d3/b715e38438f1f39edb1383aea79c578073953b25fa576fc71e\n",
            "Successfully built entropy\n",
            "Installing collected packages: entropy\n",
            "Successfully installed entropy-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M49QbDhkDHIT"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJx67zwDEJjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcadddf-d975-463b-f97f-7242f7df9a8f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJiEQY2LCZ4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a7c9dc-7229-44db-f96d-1eba28b0eff3"
      },
      "source": [
        "cd /content/drive/My Drive/dataset/SchizoPhrenia 14"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/SchizoPhrenia 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCn0gh3kDMOI"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfgtZg96ER8W"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import mne\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MaxAbsScaler"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx9M98nnyfak"
      },
      "source": [
        "from scipy import signal\n",
        "nyq = 0.5 * 250\n",
        "l=0.2\n",
        "low = l / nyq\n",
        "high = 45 / nyq\n",
        "b, a = signal.butter(4, [low,high], 'band')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9B7Fx9tCGyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "700f079e-046b-4dbe-9bc8-fb57ac0c7736"
      },
      "source": [
        "HC_files=glob.glob('HC/*.edf')    \n",
        "HC=[]\n",
        "for i in HC_files:\n",
        "    data=mne.io.read_raw_edf(i,preload=True)\n",
        "    #data.set_eeg_reference('average')\n",
        "    data=data.get_data()\n",
        "    data=signal.filtfilt(b, a, data)\n",
        "   # data=mne.filter.filter_data(data, sfreq=250, l_freq=0.1, h_freq=45)\n",
        "    #scaler=StandardScaler()        \n",
        "    #data=scaler.fit_transform(data.T)     \n",
        "    #data=maxabs_scale(data.T)\n",
        "    HC.append(data.T)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 231249  =      0.000 ...   924.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 236249  =      0.000 ...   944.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 232499  =      0.000 ...   929.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 226249  =      0.000 ...   904.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 278749  =      0.000 ...  1114.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 228749  =      0.000 ...   914.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 224999  =      0.000 ...   899.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 241249  =      0.000 ...   964.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/HC/h14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 216249  =      0.000 ...   864.996 secs...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAfS6jH9CQtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5caa0e7-13fc-4968-a70d-087af8f1fae6"
      },
      "source": [
        "SZ_files=glob.glob('SZ/*.edf')\n",
        "SZ=[]\n",
        "for i in SZ_files:\n",
        "    data=mne.io.read_raw_edf(i,preload=True)\n",
        "    #data.set_eeg_reference('average')\n",
        "    data=data.get_data()\n",
        "    data=signal.filtfilt(b, a, data)\n",
        "    #data=mne.filter.filter_data(data, sfreq=250, l_freq=0.1, h_freq=45)\n",
        "    #data=maxabs_scale(data.T)\n",
        "    SZ.append(data.T)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 211249  =      0.000 ...   844.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 286249  =      0.000 ...  1144.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 240999  =      0.000 ...   963.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 301249  =      0.000 ...  1204.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 222499  =      0.000 ...   889.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 184999  =      0.000 ...   739.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 336499  =      0.000 ...  1345.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 227749  =      0.000 ...   910.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 296249  =      0.000 ...  1184.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 212499  =      0.000 ...   849.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 339999  =      0.000 ...  1359.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 271749  =      0.000 ...  1086.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 283749  =      0.000 ...  1134.996 secs...\n",
            "Extracting EDF parameters from /content/drive/My Drive/dataset/SchizoPhrenia 14/SZ/s14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 542499  =      0.000 ...  2169.996 secs...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7woBh5ZlEbRe"
      },
      "source": [
        "def reshape(data):   \n",
        "    shape=data.ravel().shape[0]\n",
        "    s=shape%19000\n",
        "    if s!=0:\n",
        "        d=data.ravel()[s//2:-s//2].reshape(-1,1000,19)\n",
        "        #return np.swapaxes(d,1,2)   \n",
        "        return d\n",
        "    else: \n",
        "        d1=data.reshape(-1,1000,19)\n",
        "        return d1\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFKvvEyvEcC4"
      },
      "source": [
        "HC_reshaped=[]\n",
        "for i in HC:\n",
        "    HC_reshaped.append(reshape(i))\n",
        "    \n",
        "    \n",
        "SZ_reshaped=[]\n",
        "for i in SZ:\n",
        "    SZ_reshaped.append(reshape(i))   "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8rXI4sQEe_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9608f222-20e5-47b2-acc2-60a6fceb5897"
      },
      "source": [
        "HC_reshaped[0].shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(231, 1000, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVH5rTmQDPZ4"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vHod_4gETis"
      },
      "source": [
        "from scipy import stats\n",
        "import pyeeg\n",
        "from entropy import *\n",
        "import pywt\n",
        "#from nitime import algorithms as alg\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MaxAbsScaler\n",
        "from sklearn.preprocessing import StandardScaler,MaxAbsScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#import nolds\n",
        "np.warnings.filterwarnings('ignore')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA0ZCARWd6T3"
      },
      "source": [
        "# Main Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LacFqUQwFbZg"
      },
      "source": [
        "\n",
        "from scipy import stats\n",
        "import pyeeg\n",
        "from entropy import *\n",
        "def mean(data):\n",
        "    return np.mean(data,axis=0)\n",
        "    \n",
        "def std(data):\n",
        "    return np.std(data,axis=0)\n",
        "\n",
        "def ptp(data):\n",
        "    return np.ptp(data,axis=0)\n",
        "\n",
        "def var(data):\n",
        "        return np.var(data,axis=0)\n",
        "\n",
        "def minim(data):\n",
        "      return np.min(data,axis=0)\n",
        "\n",
        "\n",
        "def maxim(data):\n",
        "      return np.max(data,axis=0)\n",
        "\n",
        "def argminim(data):\n",
        "      return np.argmin(data,axis=0)\n",
        "\n",
        "\n",
        "def argmaxim(data):\n",
        "      return np.argmax(data,axis=0)\n",
        "\n",
        "def mean_square(data):\n",
        "      return np.mean(data**2,axis=0)\n",
        "\n",
        "def rms(data): #root mean square\n",
        "      return  np.sqrt(np.mean(data**2,axis=0))  \n",
        "\n",
        "def abs_diffs_signal(data):\n",
        "    return np.sum(np.abs(np.diff(data,axis=0)),axis=0)\n",
        "\n",
        "\n",
        "def skewness(data):\n",
        "    return stats.skew(data,axis=0)\n",
        "\n",
        "def kurtosis(data):\n",
        "    return stats.kurtosis(data,axis=0)\n",
        "\n",
        "def zero_crossing(data):\n",
        "    return np.argmax(np.diff(np.sign(data),axis=0),axis=0)\n",
        "\n",
        "def app_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(app_entropy(i, order=2, metric='chebyshev'))\n",
        "    return np.array(result)\n",
        "\n",
        "def perm_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(perm_entropy(i, order=3, normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def svd_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(svd_entropy(i, order=3, delay=1, normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def spectral_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(spectral_entropy(i, 100, method='welch', normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def sample_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(sample_entropy(i, order=2, metric='chebyshev'))\n",
        "    return np.array(result)\n",
        "\n",
        "\n",
        "def katz(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(katz_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "def higuchi(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(higuchi_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "\n",
        "def petrosian(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(petrosian_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "def autogressiveModelParameters(data):\n",
        "    feature = []\n",
        "    for i in data.T:\n",
        "        coeff, sig = alg.AR_est_YW(i, order=5)\n",
        "        feature.append(np.mean(coeff))\n",
        "    return np.array(feature)\n",
        "\n",
        "def teager(x):\n",
        "    for i in range(len(x)-1):\n",
        "        return x[i]**2 - (x[i-1]*x[i+1])\n",
        "\n",
        "\n",
        "def lziv_complex(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(lziv_complexity(i))\n",
        "    return np.array(result)\n",
        "\n",
        "        \n",
        "def hjorth_mobility(data):\n",
        "    return np.divide(np.std(np.diff(data,axis=0),axis=0),np.std(data,axis=0))\n",
        "\n",
        "def hjorth_complexity(data):\n",
        "    return np.divide(hjorth_mobility(np.diff(data,axis=0)),  hjorth_mobility(data))      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def concatenate_features(data):\n",
        "    return np.concatenate((mean(data),std(data),ptp(data),var(data),minim(data),maxim(data),argminim(data),argmaxim(data),\n",
        "                          mean_square(data),rms(data),abs_diffs_signal(data),\n",
        "                          skewness(data),kurtosis(data),zero_crossing(data),\n",
        "                          app_epy(data),perm_epy(data),svd_epy(data),spectral_epy(data),sample_epy(data),\n",
        "                          katz(data),higuchi(data),petrosian(data),teager(data),lziv_complex(data),\n",
        "                          hjorth_mobility(data),hjorth_complexity(data)),axis=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enEVrHoCWvtz"
      },
      "source": [
        "features1=[]\n",
        "for f in HC_reshaped:\n",
        "    feature=[]\n",
        "    for i in f:\n",
        "        feature.append(concatenate_features(i))\n",
        "    features1.append(np.mean(np.array(feature),axis=0))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKWr72BTWvt5"
      },
      "source": [
        "features2=[]\n",
        "for f in SZ_reshaped:\n",
        "    feature=[]\n",
        "    for i in f:\n",
        "        feature.append(concatenate_features(i))\n",
        "    features2.append(np.mean(np.array(feature),axis=0))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cVURnzepN0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77904727-a823-4b52-ef93-46b7e97e0651"
      },
      "source": [
        "x1=np.array(features1)        \n",
        "x2=np.array(features2)      \n",
        "\n",
        "X=np.concatenate((x1,x2),axis=0)\n",
        "\n",
        "y=np.concatenate(((np.zeros(x1.shape[0])),(np.ones(x2.shape[0]))))\n",
        "X.shape,y.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28, 494), (28,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJBuPvNEToHn"
      },
      "source": [
        "feature=X.copy()\n",
        "label=y.copy()\n",
        "from sklearn.preprocessing import scale,maxabs_scale\n",
        "feature=scale(feature)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3a10gQQ_kqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0418796d-4942-4b32-923f-18998512fa60"
      },
      "source": [
        "\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def svc_param_selection(X, y):\n",
        "    Cs = [ 0.1, 1, 10,15,20,25,30,40,50,60,70,100,120]\n",
        "    gammas = [0.0001,0.0005,0.001,0.005,0.008, 0.01, 0.1,0.3,0.5, 1]\n",
        "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
        "    grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=10)\n",
        "    grid_search.fit(X, y)\n",
        "    grid_search.best_params_\n",
        "    return grid_search.best_score_\n",
        "\n",
        "\n",
        "svc_param_selection(feature,label)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pF-532Z4iEK"
      },
      "source": [
        "feature_list=['mean','std','ptp','var','minim','maxim','argmin','argmax','mean_square','rms','abs_diffs_signal','skewness','kurtosis','zero_crossing',\n",
        "'app_epy','perm_epy','svd_epy','spectral_epy','sample_epy','katz','higuchi','petrosian','teager','lziv_complex',\n",
        "'hjorth_mobility','hjorth_complexity']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7npi1Dou6En"
      },
      "source": [
        "ch=19"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P73wA4E4llG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119b4430-6ecb-430c-b21c-ae19803a6977"
      },
      "source": [
        "feature_selected=[]\n",
        "feat_non_sorted=[]\n",
        "score_non_sorted=[]\n",
        "for i ,j in zip(range(0,feature.shape[1],ch),feature_list):\n",
        "  acc=svc_param_selection(feature[:,i:i+ch],label)\n",
        "  print(j,\" : \",acc)\n",
        "  feat_non_sorted.append(j)\n",
        "  score_non_sorted.append(acc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean  :  0.6833333333333333\n",
            "std  :  0.8333333333333333\n",
            "ptp  :  0.75\n",
            "var  :  0.6\n",
            "minim  :  0.7333333333333333\n",
            "maxim  :  0.7833333333333333\n",
            "argmin  :  0.5333333333333333\n",
            "argmax  :  0.6\n",
            "mean_square  :  0.6\n",
            "rms  :  0.8666666666666666\n",
            "abs_diffs_signal  :  0.8166666666666667\n",
            "skewness  :  0.7666666666666666\n",
            "kurtosis  :  0.65\n",
            "zero_crossing  :  0.7166666666666666\n",
            "app_epy  :  0.7333333333333333\n",
            "perm_epy  :  0.8333333333333333\n",
            "svd_epy  :  0.6666666666666666\n",
            "spectral_epy  :  0.7333333333333333\n",
            "sample_epy  :  0.7\n",
            "katz  :  0.7333333333333333\n",
            "higuchi  :  0.7166666666666666\n",
            "petrosian  :  0.8333333333333333\n",
            "teager  :  0.65\n",
            "lziv_complex  :  0.36666666666666664\n",
            "hjorth_mobility  :  0.7\n",
            "hjorth_complexity  :  0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIz9Ex424loX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706d44cf-39a6-48ad-f2a5-90bcf7785f5b"
      },
      "source": [
        "print(feat_non_sorted)\n",
        "print(score_non_sorted)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mean', 'std', 'ptp', 'var', 'minim', 'maxim', 'argmin', 'argmax', 'mean_square', 'rms', 'abs_diffs_signal', 'skewness', 'kurtosis', 'zero_crossing', 'app_epy', 'perm_epy', 'svd_epy', 'spectral_epy', 'sample_epy', 'katz', 'higuchi', 'petrosian', 'teager', 'lziv_complex', 'hjorth_mobility', 'hjorth_complexity']\n",
            "[0.6833333333333333, 0.8333333333333333, 0.75, 0.6, 0.7333333333333333, 0.7833333333333333, 0.5333333333333333, 0.6, 0.6, 0.8666666666666666, 0.8166666666666667, 0.7666666666666666, 0.65, 0.7166666666666666, 0.7333333333333333, 0.8333333333333333, 0.6666666666666666, 0.7333333333333333, 0.7, 0.7333333333333333, 0.7166666666666666, 0.8333333333333333, 0.65, 0.36666666666666664, 0.7, 0.75]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGaBeLj24lrX"
      },
      "source": [
        "score,feat  = zip(*sorted(zip(score_non_sorted, feat_non_sorted),reverse=True))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTPuv_z34us1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c5d6d4-d816-484a-ecff-6f11d7791f48"
      },
      "source": [
        "print(feat)\n",
        "print(score)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('rms', 'std', 'petrosian', 'perm_epy', 'abs_diffs_signal', 'maxim', 'skewness', 'ptp', 'hjorth_complexity', 'spectral_epy', 'minim', 'katz', 'app_epy', 'zero_crossing', 'higuchi', 'sample_epy', 'hjorth_mobility', 'mean', 'svd_epy', 'teager', 'kurtosis', 'var', 'mean_square', 'argmax', 'argmin', 'lziv_complex')\n",
            "(0.8666666666666666, 0.8333333333333333, 0.8333333333333333, 0.8333333333333333, 0.8166666666666667, 0.7833333333333333, 0.7666666666666666, 0.75, 0.75, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7166666666666666, 0.7166666666666666, 0.7, 0.7, 0.6833333333333333, 0.6666666666666666, 0.65, 0.65, 0.6, 0.6, 0.6, 0.5333333333333333, 0.36666666666666664)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tODTVwi4uwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0975639b-4793-45b7-8c05-fc1eaf6ecf2f"
      },
      "source": [
        "def del_item(a, b):\n",
        "     return [x for x in a if x not in b]\n",
        "\n",
        "\n",
        "\n",
        "#skf = StratifiedKFold(n_splits=10, random_state=2020, shuffle=False)\n",
        "acc=0\n",
        "deleted_item=[]\n",
        "for i in range(1,20):\n",
        "  feature_selected=list(feat[:i])\n",
        "  # feature_selected=del_item(feature_selected,deleted_item)\n",
        "\n",
        "  X_good=[]\n",
        "  for key,val in zip(feature_list,range(0,feature.shape[1],ch)):\n",
        "      for fe in feature_selected:\n",
        "          if key==fe:     \n",
        "              #print('key',key,'value',val,\":\",val+ch) \n",
        "              X_good.append(feature[:,val:val+ch])\n",
        "  good_feature=np.concatenate((X_good),axis=1)\n",
        "  #good_feature=np.concatenate((good_feature,non_eeg),1)\n",
        "\n",
        "\n",
        "  acc_new=svc_param_selection(good_feature,label)\n",
        "  print(i,' : ', acc_new)\n",
        "\n",
        "  # print(acc_new, good_feature.shape)\n",
        "  # if acc_new<(acc-0.01):\n",
        "  #   deleted_item.append(feature_selected.pop())\n",
        "  #   print('del item',deleted_item)\n",
        "  # else:\n",
        "  #   acc=acc_new\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1  :  0.8666666666666666\n",
            "2  :  0.8666666666666666\n",
            "3  :  0.9\n",
            "4  :  0.9\n",
            "5  :  0.9\n",
            "6  :  0.8166666666666667\n",
            "7  :  0.7833333333333333\n",
            "8  :  0.7833333333333333\n",
            "9  :  0.8166666666666667\n",
            "10  :  0.85\n",
            "11  :  0.85\n",
            "12  :  0.85\n",
            "13  :  0.85\n",
            "14  :  0.9\n",
            "15  :  0.8666666666666666\n",
            "16  :  0.8666666666666666\n",
            "17  :  0.8333333333333333\n",
            "18  :  0.8666666666666666\n",
            "19  :  0.8333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_8pLs4P4uzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634ab81d-2f6e-4ada-cca3-2d0da5a3f3df"
      },
      "source": [
        "\n",
        "feature_selected=feat[:5]\n",
        "X_good=[]\n",
        "for key,val in zip(feature_list,range(0,feature.shape[1],ch)):\n",
        "    for fe in feature_selected:\n",
        "        if key==fe:     \n",
        "            print('key',key,'value',val,\":\",val+ch) \n",
        "            X_good.append(feature[:,val:val+ch])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "key std value 19 : 38\n",
            "key rms value 171 : 190\n",
            "key abs_diffs_signal value 190 : 209\n",
            "key perm_epy value 285 : 304\n",
            "key petrosian value 399 : 418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGjz4Vnz4u2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2403819-f585-4d06-f406-086272e7bee1"
      },
      "source": [
        "good_feature=np.concatenate((X_good),axis=1)\n",
        "good_feature.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 95)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1b3fldaWB2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716dccc2-7ed6-488e-fcc6-47baa4ad0869"
      },
      "source": [
        "def svc_param_selection(X, y, nfolds):\n",
        "    Cs = [ 0.1, 1, 10,15,20,25,30,40,50,60,70,80,100,120]\n",
        "    gammas = [0.0001,0.0005,0.001,0.005,0.008, 0.01, 0.1,0.3,0.5, 1]\n",
        "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
        "    grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
        "    grid_search.fit(X, y)\n",
        "    print(grid_search.best_score_)\n",
        "    return grid_search.best_params_\n",
        "\n",
        "\n",
        "svc_param_selection(good_feature,label,10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'gamma': 0.008}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSRZnUauWCNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731be276-aced-44d7-eeaa-81b415454ff9"
      },
      "source": [
        "clf = SVC(kernel=\"rbf\", C=10,gamma=0.008, probability=True)\n",
        "acc = cross_val_score(clf,good_feature,label,cv=10)\n",
        "precision = cross_val_score(clf,good_feature,label,cv=10,scoring='precision')\n",
        "recall = cross_val_score(clf,good_feature,label,cv=10,scoring='recall')\n",
        "f1 = cross_val_score(clf,good_feature,label,cv=10,scoring='f1')\n",
        "\n",
        "print('average accuracy : ',np.array(acc).mean(),np.std(np.array(acc)))\n",
        "print('average precision : ',np.array(precision).mean(),np.std(np.array(precision)))\n",
        "print('average recall : ',np.array(recall).mean(),np.std(np.array(recall)))\n",
        "print('average f1 score : ',np.array(f1).mean(),np.std(np.array(f1)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average accuracy :  0.9 0.21343747458109497\n",
            "average precision :  0.95 0.15\n",
            "average recall :  0.9 0.2\n",
            "average f1 score :  0.9166666666666666 0.17078251276599332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw-IOgoCWTAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0ded83-9535-41cd-871f-855ed2c3e0db"
      },
      "source": [
        "def knn_param_selection(X, y, nfolds):\n",
        "    n_neighbors  = [ 3,4,5,6,7,8,9]\n",
        "    weights  = ['uniform','distance']\n",
        "    metric=['minkowski','manhattan','euclidean']\n",
        "    param_grid = {'n_neighbors': n_neighbors, 'weights' : weights,'metric':metric}\n",
        "    grid_search =GridSearchCV( KNeighborsClassifier(), param_grid, cv=nfolds,n_jobs=-1)\n",
        "    grid_search.fit(X, y)\n",
        "    print(grid_search.best_score_)\n",
        "    return grid_search.best_params_\n",
        "\n",
        "\n",
        "knn_param_selection(good_feature,label,10)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqjadvBqWWSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfc5556-94d2-498c-d4da-6a03fbee49e0"
      },
      "source": [
        "clf = KNeighborsClassifier(metric= 'manhattan', n_neighbors=4, weights= 'distance')\n",
        "acc = cross_val_score(clf,good_feature,label,cv=10)\n",
        "precision = cross_val_score(clf,good_feature,label,cv=10,scoring='precision')\n",
        "recall = cross_val_score(clf,good_feature,label,cv=10,scoring='recall')\n",
        "f1 = cross_val_score(clf,good_feature,label,cv=10,scoring='f1')\n",
        "\n",
        "print('average accuracy : ',np.array(acc).mean(),np.std(np.array(acc)))\n",
        "print('average precision : ',np.array(precision).mean(),np.std(np.array(precision)))\n",
        "print('average recall : ',np.array(recall).mean(),np.std(np.array(recall)))\n",
        "print('average f1 score : ',np.array(f1).mean(),np.std(np.array(f1)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average accuracy :  0.8 0.2666666666666667\n",
            "average precision :  0.85 0.32015621187164245\n",
            "average recall :  0.75 0.33541019662496846\n",
            "average f1 score :  0.7833333333333333 0.31666666666666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAQ5DweRWX8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2abe29-973c-4a06-df03-908fbb0c9e58"
      },
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "def logistic_param_selection(X, y, nfolds):\n",
        "    C= [0.01,0.05,0.1,0.5, 1,2,3,4,5,8, 10,12,15]\n",
        "    max_it= [200,300,400,500]\n",
        "    param_grid = {'C': C,'max_iter':max_it}\n",
        "    grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=nfolds)\n",
        "    grid_search.fit(X, y)\n",
        "    print(grid_search.best_score_)\n",
        "    return grid_search.best_params_\n",
        "\n",
        "\n",
        "logistic_param_selection(good_feature,label,10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8333333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.5, 'max_iter': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2glsDq64u69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623d41d3-c03a-4244-893e-c3301b06930f"
      },
      "source": [
        "clf = LogisticRegression(max_iter=200,C=0.5)\n",
        "acc = cross_val_score(clf,good_feature,label,cv=10)\n",
        "precision = cross_val_score(clf,good_feature,label,cv=10,scoring='precision')\n",
        "recall = cross_val_score(clf,good_feature,label,cv=10,scoring='recall')\n",
        "f1 = cross_val_score(clf,good_feature,label,cv=10,scoring='f1')\n",
        "\n",
        "print('average accuracy : ',np.array(acc).mean(),np.std(np.array(acc)))\n",
        "print('average precision : ',np.array(precision).mean(),np.std(np.array(precision)))\n",
        "print('average recall : ',np.array(recall).mean(),np.std(np.array(recall)))\n",
        "print('average f1 score : ',np.array(f1).mean(),np.std(np.array(f1)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average accuracy :  0.8333333333333333 0.22360679774997896\n",
            "average precision :  0.8166666666666667 0.32015621187164245\n",
            "average recall :  0.8 0.33166247903554\n",
            "average f1 score :  0.7966666666666666 0.31427164470671964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZiWd84kWbAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852d061c-293b-4093-e372-a31f57f8103b"
      },
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "#skf = StratifiedKFold(n_splits=10, random_state=2020, shuffle=False)\n",
        "def dtree_param_selection(X,y):\n",
        "    #create a dictionary of all values we want to test\n",
        "    param_grid = { 'criterion':['gini','entropy'],'max_features':[\"auto\", \"sqrt\", \"log2\"],'max_depth': np.arange(2, 20),'random_state':[10,20,30,40]}\n",
        "    # decision tree model\n",
        "    dtree_model=DecisionTreeClassifier()\n",
        "    #use gridsearch to test all values\n",
        "    dtree_gscv = GridSearchCV(dtree_model, param_grid, cv=10)\n",
        "    #fit model to data\n",
        "    dtree_gscv.fit(X, y)\n",
        "    print(dtree_gscv.best_score_)\n",
        "    #print(dtree_gscv.best_estimator_)\n",
        "    return dtree_gscv.best_params_\n",
        "\n",
        "dtree_param_selection(good_feature,label)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7666666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': 2,\n",
              " 'max_features': 'log2',\n",
              " 'random_state': 30}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmcAY4EAWdyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d856da41-f6cb-4094-a3a0-ef87599f4c14"
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion= 'entropy', max_depth= 3, max_features= 'log2',random_state=30)\n",
        "acc = cross_val_score(clf,good_feature,label,cv=10)\n",
        "precision = cross_val_score(clf,good_feature,label,cv=10,scoring='precision')\n",
        "recall = cross_val_score(clf,good_feature,label,cv=10,scoring='recall')\n",
        "f1 = cross_val_score(clf,good_feature,label,cv=10,scoring='f1')\n",
        "\n",
        "print('average accuracy : ',np.array(acc).mean(),np.std(np.array(acc)))\n",
        "print('average precision : ',np.array(precision).mean(),np.std(np.array(precision)))\n",
        "print('average recall : ',np.array(recall).mean(),np.std(np.array(recall)))\n",
        "print('average f1 score : ',np.array(f1).mean(),np.std(np.array(f1)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average accuracy :  0.7 0.2768874620972692\n",
            "average precision :  0.65 0.39756201472921876\n",
            "average recall :  0.7 0.4\n",
            "average f1 score :  0.6466666666666667 0.3745219174716837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so882PGqWffP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}